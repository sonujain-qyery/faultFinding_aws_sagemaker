{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f727ab5-04e1-4ac9-8c36-76f15d352c30",
   "metadata": {},
   "source": [
    "## 1. Model Selection:\n",
    "Choose Algorithm: Select an appropriate machine learning algorithm based on the nature of the problem (classification, regression, clustering, etc.), the size of the dataset, and other factors.\n",
    "\n",
    "## 2. Model Building:\n",
    "Instantiate Model: Create an instance of the chosen machine learning algorithm.\n",
    "\n",
    "Fit Model: Train the model on the training data by calling the fit() method. During training, the model learns the patterns and relationships present in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c743e6a-b380-4c58-ab34-071e35f1e2ea",
   "metadata": {},
   "source": [
    "## XGBoost (Extreme Gradient Boosting) \n",
    "\n",
    "is an advanced implementation of gradient boosting algorithm designed for efficiency, flexibility, and scalability. It is widely used in machine learning competitions and real-world applications due to its state-of-the-art performance and robustness. Here's a detailed description of XGBoost:\n",
    "\n",
    "## 1. Gradient Boosting Algorithm:\n",
    "Boosting Ensemble Method: XGBoost belongs to the family of boosting ensemble methods, where multiple weak learners (usually decision trees) are trained sequentially, and each subsequent model corrects the errors made by the previous models.\n",
    "\n",
    "Gradient Boosting: XGBoost employs the gradient boosting framework, which optimizes a differentiable loss function by iteratively fitting weak learners to the negative gradient of the loss function.\n",
    "\n",
    "## 2. Key Features of XGBoost:\n",
    "Tree Ensemble Method: XGBoost builds an ensemble of decision trees, known as a gradient boosted decision tree (GBDT), to make predictions. Each tree is added sequentially to the ensemble, and subsequent trees learn from the residuals (errors) of the previous trees.\n",
    "\n",
    "Regularization Techniques: \n",
    "XGBoost integrates various regularization techniques to prevent overfitting, including L1 (Lasso) and L2 (Ridge) regularization on leaf weights, and tree pruning to control tree depth and complexity.\n",
    "\n",
    "Customizable Loss Functions: XGBoost supports customizable loss functions for both regression and classification tasks, allowing users to define their own objectives or use predefined objectives like logistic loss, squared loss, etc.\n",
    "\n",
    "Parallel and Distributed Computing: XGBoost is highly optimized for parallel and distributed computing, leveraging multiple CPU cores and supporting distributed computing frameworks like Apache Hadoop and Apache Spark.\n",
    "\n",
    "Optimized Tree Construction: XGBoost employs a number of optimization techniques to speed up tree construction, including approximate tree learning, column block for parallelization, and out-of-core computing for handling large datasets.\n",
    "\n",
    "## 3. Advantages of XGBoost:\n",
    "High Performance: XGBoost is known for its high prediction accuracy and efficiency, making it suitable for both small and large-scale datasets.\n",
    "\n",
    "Flexibility: XGBoost can handle various types of data and tasks, including classification, regression, and ranking, and supports custom loss functions and evaluation metrics.\n",
    "\n",
    "Feature Importance: XGBoost provides built-in feature importance scores, which help in feature selection and understanding the relative importance of input features in making predictions.\n",
    "\n",
    "Robustness: XGBoost is robust to overfitting and can handle noisy data and missing values effectively, thanks to its regularization techniques and handling of missing values during tree construction.\n",
    "\n",
    "## 4. Limitations of XGBoost:\n",
    "Parameter Tuning: XGBoost requires careful parameter tuning, especially for hyperparameters like learning rate, tree depth, and regularization parameters, to achieve optimal performance.\n",
    "\n",
    "Computationally Intensive: Training an XGBoost model can be computationally intensive, especially for large datasets or deep trees, requiring substantial computational resources.\n",
    "\n",
    "Interpretability: While XGBoost provides feature importance scores, the resulting models may not be as interpretable as simpler models like decision trees or linear models.\n",
    "\n",
    "Overall, XGBoost is a powerful and versatile algorithm that excels in a wide range of machine learning tasks. With its robustness, efficiency, and flexibility, XGBoost has become a popular choice for both practitioners and researchers in the field of machine learning and data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f96da11-d6ea-44ed-be25-4cece067878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-851725479967\n",
      "<sagemaker.session.Session object at 0x7f2c6257eec0>\n"
     ]
    }
   ],
   "source": [
    "# Writing the train and test dataset to S3 bucket\n",
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "print(bucket)\n",
    "print(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf295d19-ad9d-4a17-89a5-3cefc63ee309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train data location: s3://sagemaker-us-east-1-851725479967/datasets/resnet_X_train.pkl\n",
      "y train data location: s3://sagemaker-us-east-1-851725479967/datasets/resnety_train.pkl\n",
      "X test data location: s3://sagemaker-us-east-1-851725479967/datasets/resnetX_test.pkl\n",
      "y Test data location: s3://sagemaker-us-east-1-851725479967/datasets/resnety_test.pkl\n"
     ]
    }
   ],
   "source": [
    "# Upload train dataset to S3\n",
    "X_train_data_location = session.upload_data(path=\"../datasets/resnet_X_train.pkl\",bucket=bucket, key_prefix=\"datasets\")\n",
    "y_train_data_location = session.upload_data(path=\"../datasets/resnety_train.pkl\",bucket=bucket, key_prefix=\"datasets\")\n",
    "\n",
    "\n",
    "# Upload test dataset to S3\n",
    "X_test_data_location = session.upload_data(path=\"../datasets/resnetX_test.pkl\", bucket=bucket, key_prefix=\"datasets\")\n",
    "y_test_data_location = session.upload_data(path=\"../datasets/resnety_test.pkl\",bucket=bucket, key_prefix=\"datasets\")\n",
    "\n",
    "# Print the S3 locations\n",
    "print(\"X Train data location:\", X_train_data_location)\n",
    "print(\"y train data location:\", y_train_data_location)\n",
    "print(\"X test data location:\", X_test_data_location)\n",
    "print(\"y Test data location:\", y_test_data_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b71bbae-17e0-4f64-b106-ee87acfc7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required library \n",
    "import xgboost as xgb\n",
    "import os\n",
    "import pickle\n",
    "import boto3\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9f654f-d093-4ef9-9500-dcb4fddbe9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Directory: /home/sagemaker-user/faultFinding_aws_sagemaker\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory (one level up)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Print the parent directory\n",
    "print(\"Parent Directory:\", parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58cb31e-654f-484c-9f23-c4625cc50103",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data_dir = parent_dir+'/datasets/'\n",
    "model_dir = parent_dir+'/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f1fd652-fc11-4591-8f08-45506e57af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Specify the bucket name and key (path) of the pickle file\n",
    "bucket_name = bucket\n",
    "X_train_file_key = \"datasets/resnet_X_train.pkl\"\n",
    "y_train_file_key = \"datasets/resnety_train.pkl\"\n",
    "X_test_file_key = \"datasets/resnetX_test.pkl\"\n",
    "y_test_file_key = \"datasets/resnety_test.pkl\"\n",
    "\n",
    "def loadData(file_key):\n",
    "    # Read the pickle file from S3\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    pickle_bytes = response['Body'].read()\n",
    "    # Load the pickle file from bytes\n",
    "    data = pickle.loads(pickle_bytes)\n",
    "\n",
    "    return data\n",
    "\n",
    "X_train = loadData(X_train_file_key)\n",
    "y_train =  loadData(y_train_file_key)\n",
    "X_test =  loadData(X_test_file_key)\n",
    "y_test =  loadData(y_test_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a852383-481b-4e71-a16b-58a746af0454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1484, 2048), (1484,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying the shape\n",
    "X_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a40d11cb-1ebe-46d7-9767-919c1578f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of labels\n",
    "y_train_1 = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "924c41c2-5be4-4d77-8338-5ef9c8a4e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all occurrences defective as 0 and good as 1\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]=='defective' : \n",
    "        y_train[i] = 0\n",
    "    else:\n",
    "        y_train[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a5dfa9-e8a5-4501-955b-0b3293c0dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conert it into string to int\n",
    "y_train=y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b5d7d05-c4a0-4545-804c-94fb38f4a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection\n",
    "xgb_model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3128427-20aa-4525-825c-d8cc94ffb737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "332f04bb-04be-4527-b52b-ba8736d96978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  1.0000\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = xgb_model.score(X_train,y_train)\n",
    "print(f\"Training accuracy: {train_accuracy: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b69ebc7d-41f4-4165-b162-2bcc6e24e0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sagemaker-user/faultFinding_aws_sagemaker/models/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = parent_dir+'/models/'\n",
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7de1301e-534b-43ef-b80f-8861fff9b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "with open(os.path.join(model_dir,'RESNET50_xgbClassifier_model.pkl'),'wb') as f:\n",
    "    pickle.dump(xgb_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "caa30dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "\n",
    "# Import the required library\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import pickle\n",
    "import boto3\n",
    "import argparse\n",
    "import sagemaker\n",
    "\n",
    "model_file_name = \"pipeline_model\"\n",
    "\n",
    "\n",
    "\n",
    "# Main Function\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Specify the AWS region\n",
    "    region_name = 'us-east-1'  # Change this to your desired region\n",
    "    \n",
    "    # Create a SageMaker session with the specified region\n",
    "    session = boto3.Session(region_name=region_name)\n",
    "    sagemaker_session = sagemaker.Session(boto_session=session)\n",
    "    bucket = sagemaker_session.default_bucket()\n",
    "    \n",
    "    # Initialize the S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    # Specify the bucket name and key (path) of the pickle file\n",
    "    bucket_name = bucket\n",
    "    X_train_file_key = \"datasets/resnet_X_train.pkl\"\n",
    "    y_train_file_key = \"datasets/resnety_train.pkl\"\n",
    "    X_test_file_key = \"datasets/resnetX_test.pkl\"\n",
    "    y_test_file_key = \"datasets/resnety_test.pkl\"\n",
    "\n",
    "    def loadData(file_key):\n",
    "        # Read the pickle file from S3\n",
    "        response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "        pickle_bytes = response['Body'].read()\n",
    "        # Load the pickle file from bytes\n",
    "        data = pickle.loads(pickle_bytes)\n",
    "    \n",
    "        return data\n",
    "\n",
    "    X_train = loadData(X_train_file_key)\n",
    "    y_train =  loadData(y_train_file_key)\n",
    "    X_test =  loadData(X_test_file_key)\n",
    "    y_test =  loadData(y_test_file_key)\n",
    "    \n",
    "    # Replace all occurrences defective as 0 and good as 1\n",
    "    for i in range(len(y_train)):\n",
    "        if y_train[i] == 'defective': \n",
    "            y_train[i] = 0\n",
    "        else:\n",
    "            y_train[i] = 1\n",
    "    # Conert it into string to int\n",
    "    y_train = y_train.astype(int)\n",
    "    # Model selection\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    # Train the model\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Replace all occurrences defective as 0 and good as 1\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] == 'defective':\n",
    "            y_test[i] = 0\n",
    "        else:\n",
    "            y_test[i] = 1\n",
    "    # Conert it into string to int\n",
    "    y_test = y_test.astype(int)\n",
    "    # train accuracy\n",
    "    train_accuracy = xgb_model.score(X_train, y_train)\n",
    "    # test accuracy\n",
    "    test_accuracy = xgb_model.score(X_test, y_test)\n",
    "    # Save Model\n",
    "    model_save_path = os.path.join(args.model_dir, model_file_name)\n",
    "    with open(model_save_path,'wb') as f:\n",
    "        pickle.dump(xgb_model, f)\n",
    "    print(f\"Model save at path: {model_save_path}\")\n",
    "    print(f\"Training accuracy: {train_accuracy: .4f}\")\n",
    "    print(f\"Testing accuracy: {test_accuracy: .4f}\")\n",
    "\n",
    "\n",
    "# Check if the script is being executed as the main module\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the main function\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e1fedd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "xgboost\n",
    "boto3\n",
    "sagemaker\n",
    "fsspec\n",
    "s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1789272c-da80-475a-9335-02724546270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.xlarge.\n",
      "INFO:sagemaker:Creating training-job with name: xgb-pipeline-run-2024-05-23-19-35-24-098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-23 19:35:24 Starting - Starting the training job...\n",
      "2024-05-23 19:35:39 Starting - Preparing the instances for training...\n",
      "2024-05-23 19:36:07 Downloading - Downloading input data...\n",
      "2024-05-23 19:36:37 Downloading - Downloading the training image...\n",
      "2024-05-23 19:37:13 Training - Training image download completed. Training in progress..\u001b[34m[2024-05-23 19:37:23.467 ip-10-0-242-240.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-05-23 19:37:23.490 ip-10-0-242-240.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-05-23:19:37:23:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2024-05-23:19:37:23:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-05-23:19:37:23:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2024-05-23:19:37:24:INFO] Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2024-05-23:19:37:24:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2024-05-23:19:37:24:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2024-05-23:19:37:24:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xgboost in /miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.7.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3 in /miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.17.52)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker (from -r requirements.txt (line 3))\n",
      "  Downloading sagemaker-2.221.1-py3-none-any.whl.metadata (14 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (2023.12.2)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2024.5.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /miniconda3/lib/python3.8/site-packages (from xgboost->-r requirements.txt (line 1)) (1.24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /miniconda3/lib/python3.8/site-packages (from xgboost->-r requirements.txt (line 1)) (1.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.21.0,>=1.20.52 in /miniconda3/lib/python3.8/site-packages (from boto3->-r requirements.txt (line 2)) (1.20.52)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from boto3->-r requirements.txt (line 2)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /miniconda3/lib/python3.8/site-packages (from boto3->-r requirements.txt (line 2)) (0.3.7)\u001b[0m\n",
      "\u001b[34mCollecting attrs<24,>=23.1.0 (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting boto3 (from -r requirements.txt (line 2))\n",
      "  Downloading boto3-1.34.112-py3-none-any.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting cloudpickle==2.2.1 (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-pasta (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<5.0,>=3.12 in /miniconda3/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (3.20.1)\u001b[0m\n",
      "\u001b[34mCollecting smdebug-rulesconfig==1.0.1 (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata<7.0,>=1.4.0 (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (1.2.4)\u001b[0m\n",
      "\u001b[34mCollecting pathos (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting schema (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\u001b[0m\n",
      "\u001b[34mCollecting PyYAML~=6.0 (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting platformdirs (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tblib<4,>=1.7.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (3.0.0)\u001b[0m\n",
      "\u001b[34mCollecting urllib3<3.0.0,>=1.26.8 (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /miniconda3/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (2.27.0)\u001b[0m\n",
      "\u001b[34mCollecting docker (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.6/57.6 kB 7.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /miniconda3/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (5.6.7)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.35.0,>=1.34.112 (from boto3->-r requirements.txt (line 2))\n",
      "  Downloading botocore-1.34.112-py3-none-any.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3transfer<0.11.0,>=0.10.0 (from boto3->-r requirements.txt (line 2))\n",
      "  Downloading s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore<3.0.0,>=2.5.4 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.13.0-py3-none-any.whl.metadata (21 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp!=4.0.0a0,!=4.0.0a1 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiohttp-3.9.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of aiobotocore to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore<3.0.0,>=2.5.4 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.12.4-py3-none-any.whl.metadata (21 kB)\u001b[0m\n",
      "\u001b[34m  Downloading aiobotocore-2.12.3-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading aiobotocore-2.12.2-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading aiobotocore-2.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading aiobotocore-2.12.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading aiobotocore-2.11.2-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading aiobotocore-2.11.1-py3-none-any.whl.metadata (21 kB)\u001b[0m\n",
      "\u001b[34mINFO: pip is still looking at multiple versions of aiobotocore to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading aiobotocore-2.11.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading aiobotocore-2.10.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading aiobotocore-2.9.1-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading aiobotocore-2.9.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading aiobotocore-2.8.0-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading aiobotocore-2.7.0-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34m  Downloading aiobotocore-2.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading aiobotocore-2.5.4-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2024.3.1-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /miniconda3/lib/python3.8/site-packages (from botocore<1.35.0,>=1.34.112->boto3->-r requirements.txt (line 2)) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting urllib3<3.0.0,>=1.26.8 (from sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 6.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2024.3.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2024.3.0-py3-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2024.2.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2023.12.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2023.12.1-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2023.12.1-py3-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2023.10.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2023.9.2-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2023.9.2-py3-none-any.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2023.9.1-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2023.9.1-py3-none-any.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2023.9.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2023.9.0-py3-none-any.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2023.6.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=2.5.0 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.5.3-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading aiobotocore-2.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading aiobotocore-2.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading aiobotocore-2.5.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2023.5.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2023.5.0-py3-none-any.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2023.4.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2023.4.0-py3-none-any.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2023.3.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=2.4.2 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.4.2-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2023.3.0-py3-none-any.whl.metadata (5.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2023.1.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl.metadata (5.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2022.11.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2022.11.0-py3-none-any.whl.metadata (5.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=2.4.0 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading aiobotocore-2.4.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2022.10.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2022.10.0-py3-none-any.whl.metadata (5.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2022.8.2-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2022.8.2-py3-none-any.whl.metadata (5.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2022.8.1-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2022.8.1-py3-none-any.whl.metadata (5.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2022.8.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2022.8.0-py3-none-any.whl.metadata (5.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2022.7.1-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=2.3.4 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.3.4-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2022.7.1-py3-none-any.whl.metadata (5.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2022.7.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2022.7.0-py3-none-any.whl.metadata (5.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2022.5.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2022.5.0-py3-none-any.whl.metadata (5.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=2.3.0 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.3.3.tar.gz (65 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.7/65.7 kB 6.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.3.2.tar.gz (104 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 104.8/104.8 kB 10.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.3.1.tar.gz (65 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.3/65.3 kB 5.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.3.0.tar.gz (65 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.1/65.1 kB 5.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2022.3.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=2.2.0 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.2.0.tar.gz (59 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.7/59.7 kB 6.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2022.3.0-py3-none-any.whl.metadata (5.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2022.2.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=2.1.0 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.1.2-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2022.2.0-py3-none-any.whl.metadata (5.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=2.1.0 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.1.1.tar.gz (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 6.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.1.0.tar.gz (54 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.6/54.6 kB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2022.1.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.11.1-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=2.0.1 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.0.1.tar.gz (54 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 5.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2021.11.1-py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.11.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=1.4.1 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-1.4.2.tar.gz (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.5/52.5 kB 5.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2021.11.0-py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=1.4.1 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-1.4.1.tar.gz (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.3/52.3 kB 6.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.10.1-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2021.10.1-py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.10.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2021.10.0-py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.9.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2021.9.0-py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.8.1-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2021.8.1-py3-none-any.whl.metadata (5.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=1.4.0 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-1.4.0.tar.gz (51 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.6/51.6 kB 4.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.8.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2021.7.0-py3-none-any.whl.metadata (5.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.7.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore>=1.0.1 (from s3fs->-r requirements.txt (line 5))\n",
      "  Downloading aiobotocore-2.0.0.tar.gz (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 6.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.3.tar.gz (50 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.6/50.6 kB 4.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.2.tar.gz (49 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.1/49.1 kB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.1.tar.gz (48 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.8/48.8 kB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.0.tar.gz (48 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.2/48.2 kB 4.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.2.2.tar.gz (48 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.1/48.1 kB 4.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.2.1.tar.gz (48 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.0/48.0 kB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.2.0.tar.gz (47 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.3/47.3 kB 4.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading aiobotocore-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading aiobotocore-1.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading aiobotocore-1.0.7-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading aiobotocore-1.0.6-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading aiobotocore-1.0.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading aiobotocore-1.0.4-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading aiobotocore-1.0.3-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading aiobotocore-1.0.2-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading aiobotocore-1.0.1-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.6.1-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2021.6.1-py3-none-any.whl.metadata (5.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.6.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2021.6.0-py3-none-any.whl.metadata (5.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.5.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2021.5.0-py3-none-any.whl.metadata (5.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-2021.4.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from -r requirements.txt (line 4))\n",
      "  Downloading fsspec-2021.4.0-py3-none-any.whl.metadata (5.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs (from -r requirements.txt (line 5))\n",
      "  Downloading s3fs-0.6.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading s3fs-0.5.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Downloading s3fs-0.5.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading s3fs-0.5.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading s3fs-0.4.2-py3-none-any.whl.metadata (1.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.8/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker->-r requirements.txt (line 3)) (3.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.8/site-packages (from requests->sagemaker->-r requirements.txt (line 3)) (2023.7.22)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /miniconda3/lib/python3.8/site-packages (from requests->sagemaker->-r requirements.txt (line 3)) (2.0.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /miniconda3/lib/python3.8/site-packages (from requests->sagemaker->-r requirements.txt (line 3)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.8/site-packages (from google-pasta->sagemaker->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources>=1.4.0 (from jsonschema->sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema-specifications>=2023.03.6 (from jsonschema->sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting pkgutil-resolve-name>=1.3.10 (from jsonschema->sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl.metadata (624 bytes)\u001b[0m\n",
      "\u001b[34mCollecting referencing>=0.28.4 (from jsonschema->sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting rpds-py>=0.7.1 (from jsonschema->sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading rpds_py-0.18.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker->-r requirements.txt (line 3)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mCollecting ppft>=1.7.6.8 (from pathos->sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting dill>=0.3.8 (from pathos->sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting pox>=0.3.4 (from pathos->sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting multiprocess>=0.70.16 (from pathos->sagemaker->-r requirements.txt (line 3))\n",
      "  Downloading multiprocess-0.70.16-py38-none-any.whl.metadata (7.1 kB)\u001b[0m\n",
      "\u001b[34mDownloading sagemaker-2.221.1-py3-none-any.whl (1.5 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 57.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mDownloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mDownloading boto3-1.34.112-py3-none-any.whl (139 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.3/139.3 kB 15.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading botocore-1.34.112-py3-none-any.whl (12.3 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 68.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading s3fs-0.4.2-py3-none-any.whl (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 kB 7.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mDownloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 736.6/736.6 kB 44.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.2/82.2 kB 9.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.8/143.8 kB 13.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.8/147.8 kB 13.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 5.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.3/88.3 kB 10.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pathos-0.3.2-py3-none-any.whl (82 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.1/82.1 kB 8.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 kB 8.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.3/116.3 kB 12.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mDownloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading multiprocess-0.70.16-py38-none-any.whl (132 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 13.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\u001b[0m\n",
      "\u001b[34mDownloading pox-0.3.4-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mDownloading ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 6.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading referencing-0.35.1-py3-none-any.whl (26 kB)\u001b[0m\n",
      "\u001b[34mDownloading rpds_py-0.18.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 42.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=4887 sha256=96c5b09860df660590a3a2aa14e460c1f31047b05464698e5164fdb844ba3b41\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-65ko7a1f/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train, schema, urllib3, tqdm, smdebug-rulesconfig, rpds-py, PyYAML, ppft, pox, platformdirs, pkgutil-resolve-name, importlib-resources, importlib-metadata, google-pasta, dill, cloudpickle, attrs, referencing, multiprocess, botocore, s3transfer, s3fs, pathos, jsonschema-specifications, docker, jsonschema, boto3, sagemaker\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.5\n",
      "    Uninstalling urllib3-1.26.5:\n",
      "      Successfully uninstalled urllib3-1.26.5\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 7.0.1\n",
      "    Uninstalling importlib-metadata-7.0.1:\n",
      "      Successfully uninstalled importlib-metadata-7.0.1\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 3.0.0\n",
      "    Uninstalling cloudpickle-3.0.0:\n",
      "      Successfully uninstalled cloudpickle-3.0.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.52\n",
      "    Uninstalling botocore-1.20.52:\n",
      "      Successfully uninstalled botocore-1.20.52\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.7\n",
      "    Uninstalling s3transfer-0.3.7:\n",
      "      Successfully uninstalled s3transfer-0.3.7\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.52\n",
      "    Uninstalling boto3-1.17.52:\n",
      "      Successfully uninstalled boto3-1.17.52\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires boto3==1.17.52, but you have boto3 1.34.112 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires botocore==1.20.52, but you have botocore 1.34.112 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires PyYAML==5.4.1, but you have pyyaml 6.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires urllib3==1.26.5, but you have urllib3 1.26.18 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed PyYAML-6.0.1 attrs-23.2.0 boto3-1.34.112 botocore-1.34.112 cloudpickle-2.2.1 dill-0.3.8 docker-7.1.0 google-pasta-0.2.0 importlib-metadata-6.11.0 importlib-resources-6.4.0 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 multiprocess-0.70.16 pathos-0.3.2 pkgutil-resolve-name-1.3.10 platformdirs-4.2.2 pox-0.3.4 ppft-1.7.6.8 referencing-0.35.1 rpds-py-0.18.1 s3fs-0.4.2 s3transfer-0.10.1 sagemaker-2.221.1 schema-0.7.7 smdebug-rulesconfig-1.0.1 tqdm-4.66.4 train-1.0.0 urllib3-1.26.18\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2024-05-23:19:37:46:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-05-23:19:37:46:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": 0.2,\n",
      "        \"gamma\": 4,\n",
      "        \"max_depth\": 5,\n",
      "        \"min_child_weight\": 6,\n",
      "        \"objective\": \"binary:logistic\",\n",
      "        \"subsample\": 0.8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"xgb-pipeline-run-2024-05-23-19-35-24-098\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-851725479967/xgb-pipeline-run-2024-05-23-19-35-24-098/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":0.2,\"gamma\":4,\"max_depth\":5,\"min_child_weight\":6,\"objective\":\"binary:logistic\",\"subsample\":0.8}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-851725479967/xgb-pipeline-run-2024-05-23-19-35-24-098/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":0.2,\"gamma\":4,\"max_depth\":5,\"min_child_weight\":6,\"objective\":\"binary:logistic\",\"subsample\":0.8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"xgb-pipeline-run-2024-05-23-19-35-24-098\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-851725479967/xgb-pipeline-run-2024-05-23-19-35-24-098/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--objective\",\"binary:logistic\",\"--subsample\",\"0.8\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=4\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=5\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=binary:logistic\u001b[0m\n",
      "\u001b[34mSM_HP_SUBSAMPLE=0.8\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m train --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --objective binary:logistic --subsample 0.8\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34mModel save at path: /opt/ml/model/pipeline_model\u001b[0m\n",
      "\u001b[34mTraining accuracy:  1.0000\u001b[0m\n",
      "\u001b[34mTesting accuracy:  0.9355\u001b[0m\n",
      "\n",
      "2024-05-23 19:38:16 Uploading - Uploading generated training model\n",
      "2024-05-23 19:38:16 Completed - Training job completed\n",
      "Training seconds: 129\n",
      "Billable seconds: 58\n",
      "Managed Spot Training savings: 55.0%\n"
     ]
    }
   ],
   "source": [
    "# Train with the help of sagemaker estimator\n",
    "# Choose framework\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "                          role=get_execution_role(),\n",
    "                          base_job_name=\"xgb-pipeline-run\",\n",
    "                          entry_point=\"train.py\",\n",
    "                          framework_version='1.7-1',\n",
    "                          dependencies=['requirements.txt'],\n",
    "                          instance_count=1,\n",
    "                          instance_type='ml.m5.xlarge',\n",
    "                          hyperparameters={'eta': 0.2,\n",
    "                                           'gamma': 4,\n",
    "                                           'max_depth': 5,\n",
    "                                           'min_child_weight': 6,\n",
    "                                           'objective': 'binary:logistic',\n",
    "                                           'subsample': 0.8,\n",
    "                                           },\n",
    "                          use_spot_instances=True,\n",
    "                          max_wait=600,\n",
    "                          max_run=600,\n",
    "                          )\n",
    "\n",
    "xgb_estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82fd39ea-5508-4be6-9656-ede7aa97f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model storage location: s3://sagemaker-us-east-1-851725479967/xgb-pipeline-run-2024-05-23-19-35-24-098/output/model.tar.gz\n",
      "Training Job Name: xgb-pipeline-run-2024-05-23-19-35-24-098\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# Initialize SageMaker client\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "# Get the training job name\n",
    "training_job_name = xgb_estimator.latest_training_job.name\n",
    "\n",
    "# Use the training job name to describe the training job\n",
    "model_artifact = sm_client.describe_training_job(TrainingJobName=training_job_name)[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(f\"Model storage location: {model_artifact}\")\n",
    "print(f\"Training Job Name: {training_job_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8f3b416-cdf7-46fc-803f-a133ca5cc98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: xgb-pipeline-run-240523-2007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................*\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for HyperParameterTuning job xgb-pipeline-run-240523-2007: Failed. Reason: No objective metrics found after running 5 training jobs. Please ensure that the custom algorithm is emitting the objective metric as defined by the regular expression provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 25\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m HyperparameterTuner(\n\u001b[1;32m     15\u001b[0m     base_tuning_job_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgb-pipeline-run\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mxgb_estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     max_parallel_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Launch optimizer to fit\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/tuner.py:1040\u001b[0m, in \u001b[0;36mHyperparameterTuner.fit\u001b[0;34m(self, inputs, job_name, include_cls_metadata, estimator_kwargs, wait, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_with_estimator_dict(inputs, job_name, include_cls_metadata, estimator_kwargs)\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_tuning_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/tuner.py:2345\u001b[0m, in \u001b[0;36m_TuningJob.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Placeholder docstring.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_tuning_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5180\u001b[0m, in \u001b[0;36mSession.wait_for_tuning_job\u001b[0;34m(self, job, poll)\u001b[0m\n\u001b[1;32m   5166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for an Amazon SageMaker hyperparameter tuning job to complete.\u001b[39;00m\n\u001b[1;32m   5167\u001b[0m \n\u001b[1;32m   5168\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5177\u001b[0m \u001b[38;5;124;03m    exceptions.UnexpectedStatusException: If the hyperparameter tuning job fails.\u001b[39;00m\n\u001b[1;32m   5178\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5179\u001b[0m desc \u001b[38;5;241m=\u001b[39m _wait_until(\u001b[38;5;28;01mlambda\u001b[39;00m: _tuning_job_status(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client, job), poll)\n\u001b[0;32m-> 5180\u001b[0m \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHyperParameterTuningJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:8048\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   8042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   8043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   8044\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8045\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8046\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8047\u001b[0m     )\n\u001b[0;32m-> 8048\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   8049\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8050\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8051\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8052\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for HyperParameterTuning job xgb-pipeline-run-240523-2007: Failed. Reason: No objective metrics found after running 5 training jobs. Please ensure that the custom algorithm is emitting the objective metric as defined by the regular expression provided."
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "hyperparameter_ranges = {\n",
    "    'max_depth': IntegerParameter(3, 10),\n",
    "    'eta': ContinuousParameter(0.01, 0.2),\n",
    "    'min_child_weight': IntegerParameter(1, 6),\n",
    "    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "    'gamma': ContinuousParameter(0, 10)\n",
    "}\n",
    "\n",
    "# Create Optimizer\n",
    "\n",
    "optimizer = HyperparameterTuner(\n",
    "    base_tuning_job_name=\"xgb-pipeline-run\",\n",
    "    estimator=xgb_estimator,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    objective_type=\"Maximize\",\n",
    "    objective_metric_name=\"validation:auc\",\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=2,\n",
    ")\n",
    "# Launch optimizer to fit\n",
    "\n",
    "optimizer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a41b6bf-f20c-4203-86a2-8457f6e8d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis the tunning results:\n",
    "results = optimizer.analytics().datafram()\n",
    "results.sort_values(\"Final Objective value\", ascending=False).head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
